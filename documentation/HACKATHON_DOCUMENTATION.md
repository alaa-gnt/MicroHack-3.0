# ğŸš€ APCS - Autonomous Pipeline for Corporate Scouting
## **MicroHack 3.0 Project Documentation**

---

## ğŸ“‹ Table of Contents
1. [Executive Summary](#executive-summary)
2. [System Architecture Overview](#system-architecture-overview)
3. [Tech Stack](#tech-stack)
4. [Multi-Agent System Design](#multi-agent-system-design)
5. [Backend API](#backend-api)
6. [Frontend Dashboard](#frontend-dashboard)
7. [Database Schema](#database-schema)
8. [How to Run the Project](#how-to-run-the-project)
9. [API Endpoints](#api-endpoints)
10. [Workflow Diagrams](#workflow-diagrams)

---

## ğŸ¯ Executive Summary

**APCS (Autonomous Pipeline for Corporate Scouting)** is an AI-powered innovation management platform that automates the entire lifecycle of technology signal detection, analysis, and strategic decision-making. 

### The Problem We Solve
Companies struggle to:
- Monitor emerging technologies across multiple sources
- Quickly assess which innovations are worth pursuing
- Generate actionable feasibility studies
- Create implementation blueprints for approved ideas

### Our Solution
A **fully autonomous multi-agent pipeline** that:
1. **Scrapes** technology signals from patents, RSS feeds, tech news, and academic papers
2. **Analyzes** signals using AI agents (domain classification, impact/urgency scoring)
3. **Generates** deep feasibility studies for high-potential opportunities
4. **Creates** implementation-ready blueprints with architecture, code schemas, and UI prompts

---

## ğŸ—ï¸ System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           APCS ARCHITECTURE                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚   SCRAPING      â”‚     â”‚   TIER-1 AGENTS  â”‚     â”‚   TIER-2 AGENTS  â”‚   â”‚
â”‚   â”‚   ENGINE        â”‚â”€â”€â”€â”€â–¶â”‚   (Analysis)     â”‚â”€â”€â”€â”€â–¶â”‚   (Deep Dive)    â”‚   â”‚
â”‚   â”‚  (first_graphe) â”‚     â”‚  (multiagent1)   â”‚     â”‚  (multiagent2)   â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                        â”‚                        â”‚              â”‚
â”‚           â”‚                        â”‚                        â”‚              â”‚
â”‚           â–¼                        â–¼                        â–¼              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                         PostgreSQL Database                          â”‚ â”‚
â”‚   â”‚   (signals, opportunities, feasibility_studies, blueprints)         â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                       â”‚
â”‚                                    â–¼                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                       FastAPI Backend Server                         â”‚ â”‚
â”‚   â”‚                          (REST API)                                  â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                                       â”‚
â”‚                                    â–¼                                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚                     React + Vite Dashboard                           â”‚ â”‚
â”‚   â”‚              (Dashboard, Signals, Pipeline, Alerts)                  â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚   â”‚        Redis Queue             â”‚â—€â”€â”€ Message passing between agents     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Tech Stack

### Backend
| Component | Technology | Purpose |
|-----------|------------|---------|
| API Framework | **FastAPI** (Python 3.11) | High-performance REST API |
| Database | **PostgreSQL 15** | Persistent storage |
| ORM | **SQLAlchemy 2.0** | Database interactions |
| Migrations | **Alembic** | Database versioning |
| Message Queue | **Redis** | Agent communication |
| AI Framework | **LangGraph + LangChain** | Multi-agent orchestration |
| LLM Provider | **Google Gemini 1.5 Flash** | Language model for agents |
| Authentication | **JWT (python-jose)** | Secure API access |

### Frontend
| Component | Technology | Purpose |
|-----------|------------|---------|
| Framework | **React 19** | UI framework |
| Build Tool | **Vite (rolldown)** | Fast development server |
| Routing | **React Router v7** | Page navigation |
| Charts | **ECharts** | Data visualization |
| Animations | **Framer Motion** | Smooth UI transitions |
| Markdown | **React-Markdown** | Rendering AI-generated content |
| Diagrams | **Mermaid.js** | Architecture visualizations |

### DevOps
| Component | Technology | Purpose |
|-----------|------------|---------|
| Containerization | **Docker + Docker Compose** | Service orchestration |
| Task Scheduling | **Celery** | Periodic scraping jobs |

---

## ğŸ¤– Multi-Agent System Design

### Overview
The project uses **LangGraph** to orchestrate multiple specialized AI agents in a **ReAct (Reasoning + Action) pattern**. Each agent has:
- A specific task (domain classification, impact scoring, etc.)
- Confidence-based retry logic (if confidence < 0.8, agent retries)
- State persistence via PostgreSQL checkpointing

---

### ğŸ”µ TIER-1: Signal Analysis Pipeline (`multiagent1/`)

**Purpose:** Process raw technology signals and extract structured insights.

```
START
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 1: Text Improver     â”‚ â”€â”€ Fixes grammar, improves clarity
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 2: Domain Classifier â”‚ â”€â”€ Classifies into 17 tech domains
â”‚  (ReAct Loop: retry < 0.8)  â”‚    (AI/ML, IoT, Blockchain, etc.)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 3: Impact Scorer     â”‚ â”€â”€ Rates global impact (0.0-1.0)
â”‚  (ReAct Loop: retry < 0.8)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 4: Urgency Scorer    â”‚ â”€â”€ Rates time-sensitivity (0.0-1.0)
â”‚  (ReAct Loop: retry < 0.8)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 5: TRI Calculator    â”‚ â”€â”€ Technology Readiness Index (1-9)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 6: Entity Extractor  â”‚ â”€â”€ Extracts companies, technologies,
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    locations mentioned
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database Node              â”‚ â”€â”€ Saves to `signal_analysis_opportunity`
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis Push Node            â”‚ â”€â”€ Publishes opportunity_id to queue
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    for Tier-2 processing
  â”‚
  â–¼
 END
```

**Key Files:**
- `workflow.py` - LangGraph workflow definition
- `state.py` - GraphState TypedDict with operator annotations
- `agents/` - Individual agent implementations

---

### ğŸŸ¢ TIER-2: Feasibility Deep-Dive Pipeline (`multiagent2/`)

**Purpose:** Perform in-depth analysis on promising opportunities.

```
START (Redis Event)
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 1: Tech Assessor     â”‚ â”€â”€ Detailed technical requirements
â”‚  (ReAct Loop)               â”‚    analysis with markdown report
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 2: Stack Designer    â”‚ â”€â”€ Recommends technology stack
â”‚  (ReAct Loop)               â”‚    and architecture patterns
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 3: Market Analyst    â”‚ â”€â”€ Market size, competitors,
â”‚  (ReAct Loop)               â”‚    strategic positioning
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 4: Feasibility Expert                â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚
â”‚  â•‘  PIVOT LOOP: If score < 0.5           â•‘  â”‚
â”‚  â•‘  â†’ Sends back to Stack Designer       â•‘  â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚
  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Agent 5: Strategist        â”‚ â”€â”€ Final GO/NO-GO recommendation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    and executive summary
  â”‚
  â–¼
 DATABASE (feasibility_studies table)
```

**Unique Feature:** The **Feasibility Expert** can send projects back to the Stack Designer if the initial architecture is deemed unfeasible, creating an iterative improvement loop.

---

### ğŸ”´ Graph 0: Scraping Engine (`first_graphe/`)

**Purpose:** Autonomous data collection from multiple sources.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Orchestrator   â”‚ â”€â”€ Decides when to trigger scraping
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    (every 5 hours or manual)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Parallel Scrapers              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Patents â”‚ â”‚   RSS   â”‚ â”‚ Tech News  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚        â”‚ Academic â”‚                     â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Quality Filter  â”‚ â”€â”€ Validates content integrity
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Formatter     â”‚ â”€â”€ Standardizes to schema
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Handoff      â”‚ â”€â”€ Publishes to PostgreSQL
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Scrapers Implemented:**
- `patent_scraper.py` - USPTO, Google Patents
- `rss_scraper.py` - Tech RSS feeds (TechCrunch, Wired, etc.)
- `tech_news_scraper.py` - Technology news sites
- `academic_scraper.py` - arXiv, academic papers
- `lens_scraper.py` - The Lens patent/scholarly search

---

## ğŸ–¥ï¸ Backend API

### Project Structure
```
MicroHack-3.0-Back/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py            # Environment configuration
â”‚   â”œâ”€â”€ dependencies.py      # DB session, auth dependencies
â”‚   â”œâ”€â”€ models/              # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ signal.py        # Signals table
â”‚   â”‚   â”œâ”€â”€ opportunity.py   # Analysis opportunities
â”‚   â”‚   â”œâ”€â”€ feasibility.py   # Feasibility studies
â”‚   â”‚   â”œâ”€â”€ blueprint.py     # Venture blueprints
â”‚   â”‚   â”œâ”€â”€ alert.py         # Alert notifications
â”‚   â”‚   â””â”€â”€ user.py          # User authentication
â”‚   â”œâ”€â”€ routers/             # API endpoints
â”‚   â”‚   â”œâ”€â”€ signals.py       # /api/v1/signals
â”‚   â”‚   â”œâ”€â”€ pipeline.py      # /api/v1/pipeline
â”‚   â”‚   â”œâ”€â”€ feasibility.py   # /api/v1/feasibility-studies
â”‚   â”‚   â”œâ”€â”€ blueprints.py    # /api/v1/blueprints
â”‚   â”‚   â”œâ”€â”€ alerts.py        # /api/v1/alerts
â”‚   â”‚   â”œâ”€â”€ analytics.py     # /api/v1/analytics
â”‚   â”‚   â””â”€â”€ auth.py          # /api/v1/auth
â”‚   â”œâ”€â”€ services/            # Business logic layer
â”‚   â”‚   â”œâ”€â”€ signal_service.py
â”‚   â”‚   â”œâ”€â”€ blueprint_service.py  # AI-powered blueprint generation
â”‚   â”‚   â””â”€â”€ feasibility_service.py
â”‚   â””â”€â”€ schemas/             # Pydantic request/response models
â”œâ”€â”€ micro_hack/
â”‚   â”œâ”€â”€ multiagent1/         # Tier-1 analysis agents
â”‚   â””â”€â”€ multiagent2/         # Tier-2 feasibility agents
â”œâ”€â”€ first_graphe/            # Scraping engine
â”œâ”€â”€ docker-compose.yml       # Service orchestration
â”œâ”€â”€ Dockerfile               # Backend container
â””â”€â”€ requirements.txt         # Python dependencies
```

---

## ğŸ¨ Frontend Dashboard

### Project Structure
```
apcs-dashbord/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.jsx              # Main router setup
â”‚   â”œâ”€â”€ main.jsx             # Entry point
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ Dashboard/       # Main overview with stats
â”‚   â”‚   â”œâ”€â”€ SignalsInbox/    # View/accept/reject signals
â”‚   â”‚   â”œâ”€â”€ InnovationPipeline/  # Stage-based project tracking
â”‚   â”‚   â”œâ”€â”€ TechnologyTrends/    # Tech radar visualization
â”‚   â”‚   â”œâ”€â”€ Alerts/          # Alert management
â”‚   â”‚   â”œâ”€â”€ FeasibilityDetail/   # Deep-dive analysis view
â”‚   â”‚   â””â”€â”€ BlueprintWorkspace/  # AI-generated blueprints
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ dashboard/       # StatCard, TechnologySignal
â”‚   â”‚   â”œâ”€â”€ signals/         # SignalCard components
â”‚   â”‚   â”œâ”€â”€ pipeline/        # PipelineStageCard, ProjectCard
â”‚   â”‚   â”œâ”€â”€ common/          # FilterTabs, Mermaid renderer
â”‚   â”‚   â””â”€â”€ layout/          # Header, Sidebar, Layout
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ api.js           # Base API client
â”‚   â”‚   â”œâ”€â”€ signalsService.js
â”‚   â”‚   â”œâ”€â”€ feasibilityService.js
â”‚   â”‚   â””â”€â”€ blueprintService.js
â”‚   â”œâ”€â”€ hooks/               # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useSignals.js
â”‚   â”‚   â”œâ”€â”€ usePipelineData.js
â”‚   â”‚   â””â”€â”€ useDashboardData.js
â”‚   â””â”€â”€ context/
â”‚       â””â”€â”€ AuthContext.jsx  # Authentication state
â””â”€â”€ package.json
```

### Key Pages

| Page | Route | Description |
|------|-------|-------------|
| Dashboard | `/` | Overview with stats, recent signals |
| Signals Inbox | `/signals-inbox` | Filter and review opportunity sheets |
| Innovation Pipeline | `/innovation-pipeline` | Kanban-style stage tracking |
| Technology Trends | `/technology-trends` | Tech radar visualization |
| Alerts | `/alerts` | Alert rule management |
| Feasibility Detail | `/feasibility/:id` | Deep-dive analysis report |
| Blueprint Workspace | `/blueprint/:id` | AI-generated implementation guide |

---

## ğŸ—„ï¸ Database Schema

```sql
-- Core Tables
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          signals                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)          â”‚ VARCHAR    â”‚ UUID                           â”‚
â”‚ title            â”‚ VARCHAR    â”‚ Signal headline                â”‚
â”‚ full_content     â”‚ TEXT       â”‚ Complete signal text           â”‚
â”‚ source_url       â”‚ VARCHAR    â”‚ Origin URL                     â”‚
â”‚ source_name      â”‚ VARCHAR    â”‚ Source (TechCrunch, arXiv)     â”‚
â”‚ date             â”‚ TIMESTAMP  â”‚ Detection date                 â”‚
â”‚ is_processed     â”‚ BOOLEAN    â”‚ Tier-1 completion flag         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ 1:1
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 signal_analysis_opportunity                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)          â”‚ VARCHAR    â”‚ UUID                           â”‚
â”‚ signal_id (FK)   â”‚ VARCHAR    â”‚ Link to signal                 â”‚
â”‚ primary_domain   â”‚ VARCHAR    â”‚ AI/ML, IoT, Blockchain, etc.   â”‚
â”‚ urgency_score    â”‚ INTEGER    â”‚ 0-10 scale                     â”‚
â”‚ impact_score     â”‚ INTEGER    â”‚ 0-10 scale                     â”‚
â”‚ estimated_trl    â”‚ INTEGER    â”‚ Technology Readiness (1-9)     â”‚
â”‚ companies_mentioned â”‚ TEXT    â”‚ Extracted companies            â”‚
â”‚ technologies_mentioned â”‚ TEXT â”‚ Extracted technologies         â”‚
â”‚ locations_mentioned â”‚ TEXT    â”‚ Extracted locations            â”‚
â”‚ corrected_text   â”‚ TEXT       â”‚ AI-improved signal text        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ 1:1
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     feasibility_studies                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)          â”‚ VARCHAR    â”‚ UUID                           â”‚
â”‚ opportunity_id   â”‚ VARCHAR    â”‚ Link to opportunity            â”‚
â”‚ technical_assessment â”‚ TEXT   â”‚ Markdown technical report      â”‚
â”‚ required_technology_stack â”‚ TEXT â”‚ Recommended stack           â”‚
â”‚ market_analysis  â”‚ TEXT       â”‚ Market size, competitors       â”‚
â”‚ overall_feasibility â”‚ VARCHAR â”‚ GO / MAYBE / NO-GO             â”‚
â”‚ final_recommendation â”‚ VARCHAR â”‚ Executive summary             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ 1:1
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     venture_blueprints                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)          â”‚ VARCHAR    â”‚ UUID                           â”‚
â”‚ opportunity_id   â”‚ VARCHAR    â”‚ Link to opportunity            â”‚
â”‚ system_architecture â”‚ TEXT    â”‚ Architecture description       â”‚
â”‚ data_schema      â”‚ TEXT       â”‚ Database models/schemas        â”‚
â”‚ security_protocols â”‚ TEXT     â”‚ Security recommendations       â”‚
â”‚ kpi_metrics      â”‚ TEXT       â”‚ Success metrics                â”‚
â”‚ v0_prompt        â”‚ TEXT       â”‚ Prompt for v0.dev/Artifacts    â”‚
â”‚ github_manifest  â”‚ JSONB      â”‚ package.json, README, .env     â”‚
â”‚ mermaid_flow     â”‚ TEXT       â”‚ Architecture diagram code      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ How to Run the Project

### Prerequisites
- **Docker** and **Docker Compose** installed
- **Node.js 18+** for frontend
- **Python 3.11+** for agents (if running locally)
- **Google API Key** for Gemini LLM

### Environment Variables
Create a `.env` file in `MicroHack-3.0-Back/`:
```env
# Database
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=microhack
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# AI Keys
GOOGLE_API_KEY=your_google_api_key_here

# Optional
MISTRAL_API_KEY=your_mistral_key_here
```

---

### Option 1: Docker Compose (Recommended)

```bash
# 1. Navigate to backend directory
cd MicroHack-3.0-Back

# 2. Start all services (PostgreSQL, Redis, API)
docker-compose up -d

# 3. Run database migrations
docker exec -it microhack_app alembic upgrade head

# 4. Seed initial data (optional)
docker exec -it microhack_app python seed_data.py

# 5. Start the frontend
cd ../apcs-dashbord
npm install
npm run dev

# 6. Access the application
# Frontend: http://localhost:5173
# Backend API: http://localhost:8000
# API Docs: http://localhost:8000/docs
```

---

### Option 2: Manual Setup

#### Step 1: Start Database and Redis
```bash
# Start PostgreSQL
docker run -d --name microhack_db \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=microhack \
  -p 5432:5432 \
  postgres:15-alpine

# Start Redis
docker run -d --name microhack_redis \
  -p 6379:6379 \
  redis:7-alpine
```

#### Step 2: Backend API Server
```bash
cd MicroHack-3.0-Back

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Run migrations
alembic upgrade head

# Start the server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

#### Step 3: Tier-1 Agents (Signal Analysis)
```bash
cd MicroHack-3.0-Back/micro_hack/multiagent1

# Install agent dependencies
pip install -r requirements.txt

# Run the pipeline manually (for testing)
python main.py

# OR run the watcher (listens for new signals)
python main_watcher.py
```

#### Step 4: Tier-2 Agents (Feasibility Deep-Dive)
```bash
cd MicroHack-3.0-Back/micro_hack/multiagent2

# Install dependencies
pip install -r requirements.txt

# Start the Redis watcher (waits for Tier-1 outputs)
python main_watcher.py
```

#### Step 5: Frontend Dashboard
```bash
cd apcs-dashbord

# Install dependencies
npm install

# Start development server
npm run dev

# Access at http://localhost:5173
```

---

### Running the Scraping Engine (Optional)

```bash
cd MicroHack-3.0-Back/first_graphe

# Setup
cp .env.example .env
pip install -r requirements.txt

# Manual trigger
python scripts/manual_trigger.py

# Start scheduled scraping (every 5 hours)
celery -A scheduler.celery_app worker --loglevel=info
celery -A scheduler.celery_app beat --loglevel=info
```

---

## ğŸ“¡ API Endpoints

### Authentication
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/auth/login` | User login, returns JWT |
| POST | `/api/v1/auth/register` | Create new user |

### Signals
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/v1/signals` | List all signals |
| GET | `/api/v1/signals?category=AI%2FML` | Filter by domain |
| GET | `/api/v1/signals/{id}` | Get single signal with analysis |

### Pipeline
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/v1/pipeline/stages` | Get pipeline stage counts |
| GET | `/api/v1/pipeline/projects?stage=2` | Get projects by stage |

### Feasibility Studies
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/v1/feasibility-studies/{opportunity_id}` | Get feasibility study |

### Venture Blueprints
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/v1/blueprints/{opportunity_id}` | Get existing blueprint |
| POST | `/api/v1/blueprints/{opportunity_id}/generate` | Generate new blueprint |
| POST | `/api/v1/blueprints/{opportunity_id}/generate?force=true` | Regenerate |

### Analytics
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/v1/analytics/dashboard` | Dashboard metrics |
| GET | `/api/v1/analytics/trends` | Technology trend data |

### Alerts
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/v1/alerts` | List active alerts |
| POST | `/api/v1/alert-rules` | Create alert rule |

---

## ğŸ“Š Workflow Diagrams

### Complete System Flow
```mermaid
graph LR
    subgraph "Data Collection"
        S[Scraping Engine] --> DB[(PostgreSQL)]
    end
    
    subgraph "Analysis Pipeline"
        DB --> T1[Tier-1 Agents]
        T1 --> |opportunity_id| R[(Redis Queue)]
        R --> T2[Tier-2 Agents]
        T2 --> DB
    end
    
    subgraph "User Interface"
        DB --> API[FastAPI Backend]
        API --> FE[React Dashboard]
    end
```

### Tier-1 Agent ReAct Pattern
```mermaid
graph TD
    A[Signal Input] --> B[Text Improver]
    B --> C{Domain Classifier}
    C -->|conf < 0.8| C
    C -->|conf >= 0.8| D{Impact Scorer}
    D -->|conf < 0.8| D
    D -->|conf >= 0.8| E{Urgency Scorer}
    E -->|conf < 0.8| E
    E -->|conf >= 0.8| F[TRI Calculator]
    F --> G[Entity Extractor]
    G --> H[Save to DB]
    H --> I[Push to Redis]
```

---

## ğŸ† Key Innovation Highlights

1. **Multi-Tier Agent Architecture**
   - Tier-1 for rapid signal triage (6 specialized agents)
   - Tier-2 for deep feasibility analysis (5 specialized agents)
   - Asynchronous communication via Redis

2. **ReAct Pattern Implementation**
   - Confidence-based retry loops
   - Self-improving agent outputs
   - Pivot loops (e.g., Feasibility â†’ Stack Designer)

3. **AI-Powered Blueprint Generation**
   - Automatically generates:
     - System architecture
     - Database schemas
     - Security protocols
     - KPI metrics
     - v0.dev prompts for instant UI generation
     - GitHub starter kit (package.json, README, .env)
     - Mermaid architecture diagrams

4. **End-to-End Automation**
   - From raw web scraping to implementation-ready blueprints
   - No manual intervention required
   - Real-time dashboard for monitoring

---

## ğŸ‘¥ Team & Contact

**Project:** APCS - Autonomous Pipeline for Corporate Scouting  
**Event:** MicroHack 3.0  
**Date:** February 2026

---

## ğŸ“„ License

This project was developed for MicroHack 3.0 hackathon purposes.

---

*Documentation generated for hackathon jury evaluation*
